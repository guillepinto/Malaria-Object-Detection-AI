{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T18:25:12.736726Z",
     "iopub.status.busy": "2024-11-17T18:25:12.736225Z",
     "iopub.status.idle": "2024-11-17T18:25:43.806931Z",
     "shell.execute_reply": "2024-11-17T18:25:43.805895Z",
     "shell.execute_reply.started": "2024-11-17T18:25:12.736677Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your GitHub token:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/challenge-malaria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'challenge-malaria' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "# Clone the private repository in Colab\n",
    "token = getpass('Enter your GitHub token: ')\n",
    "repo_url = f\"https://{token}:x-oauth-basic@github.com/guillepinto/Malaria-Object-Detection-AI.git\"\n",
    "\n",
    "# Switch to the necessary branch\n",
    "branch = \"main\"\n",
    "\n",
    "# Command to clone the repository\n",
    "os.system(f\"git clone -b {branch} {repo_url}\")\n",
    "\n",
    "# Access to the repo\n",
    "%cd Malaria-Object-Detection-AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T18:25:43.810053Z",
     "iopub.status.busy": "2024-11-17T18:25:43.809188Z",
     "iopub.status.idle": "2024-11-17T18:26:53.470846Z",
     "shell.execute_reply": "2024-11-17T18:26:53.469524Z",
     "shell.execute_reply.started": "2024-11-17T18:25:43.809999Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m pip install -U pip\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-24.3.1\n",
      "python -m pip install -r requirements.txt\n",
      "Collecting git+https://github.com/huggingface/transformers.git (from -r requirements.txt (line 8))\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-934bjwsp\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-934bjwsp\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 13493215abceafc1653af88b045120014fb4c1fc\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: albumentations>=1.4.16 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.4.17)\n",
      "Requirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.4.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (3.0.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.34.2)\n",
      "Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.0.9)\n",
      "Collecting pycocotools (from -r requirements.txt (line 6))\n",
      "  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.18.3)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations>=1.4.16->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations>=1.4.16->-r requirements.txt (line 1)) (1.14.1)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from albumentations>=1.4.16->-r requirements.txt (line 1)) (0.23.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations>=1.4.16->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from albumentations>=1.4.16->-r requirements.txt (line 1)) (2.9.2)\n",
      "Requirement already satisfied: albucore==0.0.17 in /opt/conda/lib/python3.10/site-packages (from albumentations>=1.4.16->-r requirements.txt (line 1)) (0.0.17)\n",
      "Requirement already satisfied: eval-type-backport in /opt/conda/lib/python3.10/site-packages (from albumentations>=1.4.16->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/lib/python3.10/site-packages (from albumentations>=1.4.16->-r requirements.txt (line 1)) (4.10.0.84)\n",
      "Requirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics->-r requirements.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics->-r requirements.txt (line 2)) (0.11.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (3.15.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->-r requirements.txt (line 3)) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 3)) (0.25.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 4)) (5.9.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 4)) (0.4.5)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm->-r requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools->-r requirements.txt (line 6)) (3.7.5)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (3.11.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (3.20.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (2.15.0)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 7)) (70.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.47.0.dev0->-r requirements.txt (line 8)) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers==4.47.0.dev0->-r requirements.txt (line 8)) (0.20.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 7)) (4.0.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 6)) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 6)) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 6)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations>=1.4.16->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.7.0->albumentations>=1.4.16->-r requirements.txt (line 1)) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets->-r requirements.txt (line 3)) (2024.8.30)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations>=1.4.16->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations>=1.4.16->-r requirements.txt (line 1)) (2.34.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations>=1.4.16->-r requirements.txt (line 1)) (2024.5.22)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations>=1.4.16->-r requirements.txt (line 1)) (0.4)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics->-r requirements.txt (line 2)) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics->-r requirements.txt (line 2)) (3.1.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 3)) (2024.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 7)) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics->-r requirements.txt (line 2)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics->-r requirements.txt (line 2)) (1.3.0)\n",
      "Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.47.0.dev0-py3-none-any.whl size=10052486 sha256=f2dac98a1a8fe3252eb6ea45c49581c10ceca525540c655c4ccb32093c03b763\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-e9wbnbpt/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
      "Successfully built transformers\n",
      "Installing collected packages: pycocotools, transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.45.1\n",
      "    Uninstalling transformers-4.45.1:\n",
      "      Successfully uninstalled transformers-4.45.1\n",
      "Successfully installed pycocotools-2.0.8 transformers-4.47.0.dev0\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "! make requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T18:26:53.472873Z",
     "iopub.status.busy": "2024-11-17T18:26:53.472443Z",
     "iopub.status.idle": "2024-11-17T18:26:54.110284Z",
     "shell.execute_reply": "2024-11-17T18:26:54.109169Z",
     "shell.execute_reply.started": "2024-11-17T18:26:53.472829Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# log in hugging face hug to load data and models\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"\", add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T18:26:54.113119Z",
     "iopub.status.busy": "2024-11-17T18:26:54.112751Z",
     "iopub.status.idle": "2024-11-17T18:26:57.710649Z",
     "shell.execute_reply": "2024-11-17T18:26:57.709580Z",
     "shell.execute_reply.started": "2024-11-17T18:26:54.113079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log in wand to track the experiments\n",
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T18:26:57.712576Z",
     "iopub.status.busy": "2024-11-17T18:26:57.712017Z",
     "iopub.status.idle": "2024-11-17T18:27:01.741341Z",
     "shell.execute_reply": "2024-11-17T18:27:01.740303Z",
     "shell.execute_reply.started": "2024-11-17T18:26:57.712521Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from accelerate import notebook_launcher\n",
    "from accelerate.utils import write_basic_config\n",
    "\n",
    "# Configure accelerate\n",
    "write_basic_config(mixed_precision=\"fp16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-17T12:00:33.821642Z",
     "iopub.status.busy": "2024-11-17T12:00:33.821207Z",
     "iopub.status.idle": "2024-11-17T12:00:48.569541Z",
     "shell.execute_reply": "2024-11-17T12:00:48.568325Z",
     "shell.execute_reply.started": "2024-11-17T12:00:33.821604Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running:  accelerate-launch /opt/conda/lib/python3.10/site-packages/accelerate/test_utils/scripts/test_script.py\n",
      "stderr: /opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "stderr:   self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "stderr: /opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "stderr:   self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "stderr: /opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "stderr:   self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "stdout: **Initialization**\n",
      "stdout: Testing, testing. 1, 2, 3.\n",
      "stdout: Distributed environment: NO\n",
      "stdout: Num processes: 1\n",
      "stdout: Process index: 0\n",
      "stdout: Local process index: 0\n",
      "stdout: Device: cuda\n",
      "stdout: \n",
      "stdout: Mixed precision type: fp16\n",
      "stdout: \n",
      "stdout: \n",
      "stdout: **Test process execution**\n",
      "stdout: \n",
      "stdout: **Test split between processes as a list**\n",
      "stdout: \n",
      "stdout: **Test split between processes as a dict**\n",
      "stdout: \n",
      "stdout: **Test split between processes as a tensor**\n",
      "stdout: \n",
      "stdout: **Test split between processes evenly**\n",
      "stdout: \n",
      "stdout: **Test split between processes as a datasets.Dataset**\n",
      "stdout: \n",
      "stdout: **Test random number generator synchronization**\n",
      "stdout: All rng are properly synched.\n",
      "stdout: \n",
      "stdout: **DataLoader integration test**\n",
      "stdout: 0 tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "stdout:         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
      "stdout:        device='cuda:0') <class 'accelerate.data_loader.DataLoaderShard'>\n",
      "stdout: Non-shuffled dataloader passing.\n",
      "stdout: Shuffled dataloader passing.\n",
      "stdout: Non-shuffled central dataloader passing.\n",
      "stdout: Shuffled central dataloader passing.\n",
      "stdout: \n",
      "stdout: **Training integration test**\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Training yielded the same results on one CPU or distributed setup with no batch split.\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Training yielded the same results on one CPU or distributes setup with batch split.\n",
      "stdout: FP16 training check.\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Keep fp32 wrapper check.\n",
      "stdout: BF16 training check.\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Training yielded the same results on one CPU or distributed setup with no batch split.\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Training yielded the same results on one CPU or distributes setup with batch split.\n",
      "stdout: FP16 training check.\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: Keep fp32 wrapper check.\n",
      "stdout: BF16 training check.\n",
      "stdout: Model dtype: torch.float32, torch.float32. Input dtype: torch.float32\n",
      "stdout: \n",
      "stdout: **Breakpoint trigger test**\n",
      "stdout: \n",
      "stdout: **Test reinstantiated state**\n",
      "Test is a success! You are ready for your distributed training!\n"
     ]
    }
   ],
   "source": [
    "! accelerate test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the script content\n",
    "script_content = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "# Configuración de variables\n",
    "MODEL_NAME=\"microsoft/conditional-detr-resnet-50\"\n",
    "DATASET_NAME=\"SemilleroCV/lacuna_malaria\"\n",
    "OUTPUT_DIR=\"conditional-detr\"\n",
    "NUM_TRAIN_EPOCHS=5\n",
    "CHECKPOINTING_STEPS=1000\n",
    "IMAGE_SQUARE_SIZE=800\n",
    "TRAIN_BATCH_SIZE=18\n",
    "EVAL_BATCH_SIZE=18\n",
    "LEARNING_RATE=2e-4\n",
    "GRADIENT_ACCUMULATION_STEPS=1\n",
    "ADAM_BETA1=0.9\n",
    "ADAM_BETA2=0.999\n",
    "ADAM_EPSILON=1e-8\n",
    "LR_SCHEDULER_TYPE=\"linear\"\n",
    "NUM_WARMUP_STEPS=0\n",
    "IGNORE_MISMATCHED_SIZES=\"--ignore_mismatched_sizes\"\n",
    "WITH_TRACKING=\"--with_tracking\"\n",
    "PUSH_TO_HUB=\"--push_to_hub\"\n",
    "REPORT_TO=\"wandb\"\n",
    "WANDB_PROJECT=\"challenge-malaria\"\n",
    "SEED=3407\n",
    "\n",
    "# CHECKPOINT=\"Microsoft-conditional-detr/step_2000\"\n",
    "\n",
    "EFFECTIVE_BATCH_SIZE=$((TRAIN_BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS))\n",
    "MODEL_ID=\"SemilleroCV/${OUTPUT_DIR}-${MAX_TRAIN_STEPS}steps\"\n",
    "\n",
    "# Generación del nuevo nombre del archivo basado en la configuración\n",
    "NEW_SCRIPT_NAME=\"${OUTPUT_DIR}_1x${EFFECTIVE_BATCH_SIZE}-${MAX_TRAIN_STEPS}-${IMAGE_SQUARE_SIZE}.sh\"\n",
    "\n",
    "# Llamada al script de entrenamiento\n",
    "accelerate launch run_object_detection_no_trainer.py \\\\\n",
    "    --model_name_or_path \"$MODEL_NAME\" \\\\\n",
    "    --dataset_name \"$DATASET_NAME\" \\\\\n",
    "    --output_dir \"$OUTPUT_DIR\" \\\\\n",
    "    --num_train_epochs $NUM_TRAIN_EPOCHS \\\\\n",
    "    --image_square_size $IMAGE_SQUARE_SIZE \\\\\n",
    "    --per_device_train_batch_size $TRAIN_BATCH_SIZE \\\\\n",
    "    --per_device_eval_batch_size $EVAL_BATCH_SIZE \\\\\n",
    "    --checkpointing_steps $CHECKPOINTING_STEPS \\\\\n",
    "    --learning_rate $LEARNING_RATE \\\\\n",
    "    --gradient_accumulation_steps $GRADIENT_ACCUMULATION_STEPS \\\\\n",
    "    --adam_beta1 $ADAM_BETA1 \\\\\n",
    "    --adam_beta2 $ADAM_BETA2 \\\\\n",
    "    --adam_epsilon $ADAM_EPSILON \\\\\n",
    "    --lr_scheduler_type $LR_SCHEDULER_TYPE \\\\\n",
    "    --num_warmup_steps $NUM_WARMUP_STEPS \\\\\n",
    "    $IGNORE_MISMATCHED_SIZES \\\\\n",
    "    $WITH_TRACKING \\\\\n",
    "    --report_to $REPORT_TO \\\\\n",
    "    --wandb_project \"$WANDB_PROJECT\" \\\\\n",
    "    --seed $SEED \\\\\n",
    "    #--resume_from_checkpoint \"$CHECKPOINT\" \\\\\n",
    "    #$PUSH_TO_HUB \\\\\n",
    "    #--hub_model_id \"$MODEL_ID\" \\\\\n",
    "\n",
    "# Renombrar el archivo script\n",
    "mv \"$0\" \"scripts/$NEW_SCRIPT_NAME\"\n",
    "\"\"\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "!mkdir -p scripts\n",
    "\n",
    "# Write the script to a file inside the scripts folder\n",
    "with open('scripts/script.sh', 'w') as f:\n",
    "    f.write(script_content)\n",
    "\n",
    "# Make the script executable\n",
    "!chmod +x scripts/script.sh\n",
    "\n",
    "# List files to confirm it's created\n",
    "!ls scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sh /kaggle/working/Malaria-Object-Detection-AI/scripts/script.sh"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
